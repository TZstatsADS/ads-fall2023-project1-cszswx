---
title: "Project1"
author: "Jianjie Sun"
date: "2023-09-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load package
```{r}
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(wordcloud2)
library(gridExtra)
library(ggplot2)
```

# Read data
# hm for cleaned_hm.csv
# demo for demographic.csv
```{r}
hm_path <- "/Users/jaysun/Downloads/HappyDB-master/happydb/data/cleaned_hm.csv"
demo_path <- "/Users/jaysun/Downloads/HappyDB-master/happydb/data/demographic.csv"

hm_data <- read_csv(hm_path)
demo_data <- read_csv(demo_path)
```

# Text preprocessing
```{r}
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm)) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords("en")) %>%
  tm_map(stripWhitespace)
```

# Stemming and tokenizing
```{r}
stemmed <- tm_map(corpus, stemDocument) %>%
  tidy() %>%
  select(text)

dict <- tidy(corpus) %>%
  select(text) %>%
  unnest_tokens(dictionary, text)
```



# Update stop words
```{r}
extra_stop_words <- c("happy","ago","yesterday","lot","today","months","month",
                      "happier","happiest","last","week","past")
stop_words <- stop_words %>% bind_rows(tibble(word = extra_stop_words, lexicon = "custom"))
```

# Create the 'completed' data frame
```{r}
completed <- stemmed %>%
  mutate(id = row_number()) %>%
  unnest_tokens(stems, text) %>%
  bind_cols(dict) %>%
  anti_join(stop_words, by = c("dictionary" = "word"))

completed_final <- completed %>%
  group_by(stems) %>%
  count(dictionary) %>%
  mutate(word = dictionary[which.max(n)]) %>%
  ungroup() %>%
  select(stems, word) %>%
  distinct()

completed_final <- completed_final %>%
  right_join(completed, by = "stems") %>%
  select(-stems) %>%
  group_by(id) %>%
  summarise(text = str_c(word, collapse = " ")) %>%
  ungroup()
```


# Merge with original data

```{r}
hm_data <- hm_data %>%
  mutate(id = row_number()) %>%
  inner_join(completed_final, by = "id")
head(hm_data)
```

# Save the processed data back to CSV
```{r}
output_path <- "/Users/jaysun/Desktop/R_programming/processed_data.csv"
write_csv(hm_data, output_path)
```


# Function to count words in a text string
```{r}
word_count <- function(text) {
  sum(str_count(text, "\\S+"))
}
```

# Process and filter data
```{r}
hm_data <- hm_data %>%
  inner_join(demo_data, by = "wid") %>%
  select(
    wid,
    original_hm,
    gender,
    marital,
    parenthood,
    reflection_period,
    age,
    country,
    ground_truth_category,
    text
  ) %>%
  mutate(count = str_count(text, "\\S+")) %>%  # Count words
  filter(
    gender %in% c("m", "f"),
    marital %in% c("single", "married"),
    parenthood %in% c("n", "y"),
    reflection_period %in% c("24h", "3m")
  ) %>%
  mutate(reflection_period = fct_recode(reflection_period, months_3 = "3m", hours_24 = "24h"))

# View first few rows of the processed data
head(hm_data)
```



# Create Bag of Words
```{r}
bag_of_words <- hm_data %>%
  unnest_tokens(word, text)

# Count frequency of each word
word_count <- bag_of_words %>%
  count(word, sort = TRUE)

# Create Bigrams and Count Them
hm_bigrams <- hm_data %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

bigram_counts <- hm_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  count(word1, word2, sort = TRUE) %>%
  filter(n > 1)  # Filtering bigrams with more than one occurrence

# Filter to only include words with more than 3100 occurrences
wc <- word_count %>% filter(n > 3100)
```


# Create plots
```{r}
# Create a bar plot where color varies by count
ggplot(data = wc, aes(x = reorder(word, -n), y = n, fill = n)) + 
  geom_bar(stat = "identity") + 
  scale_fill_gradient("Count", low = "blue", high = "red") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Create boxplot for word count
ggplot(data = word_count, aes(y = n)) +
  geom_boxplot() +
  ylab('Word Frequency') +
  ggtitle('Boxplot of Word Frequencies')
```

# Function to generate ggplot
```{r}
generate_plot <- function(data, xlab_name, ylab_name, title_name) {
  ggplot(data, aes(x = !!sym(names(data)[2]), y = !!sym(names(data)[3]), 
                   color = abs(!!sym(names(data)[3]) - !!sym(names(data)[2])))) +
    geom_point() +
    geom_abline(color = "red", lty = 2) +
    geom_jitter(alpha = 0.1, size = 1, width = 0.3, height = 0.3) +
    geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
    ggtitle(title_name) +
    xlab(xlab_name) + ylab(ylab_name) +
    scale_x_log10(labels = scales::percent_format(), limits = c(0.05, 1)) +
    scale_y_log10(labels = scales::percent_format(), limits = c(0.05, 1)) +
    scale_color_gradient(low = "blue", high = "red") +
    theme(legend.position="none")
}
```


# Dummy 'bag_of_words' data, replace with your actual data
```{r}
bag_of_words <- data.frame(parenthood = c('Yes', 'No', 'No'), word = c('apple', 'apple', 'banana'),
                           reflection_period = c('24 hours', '3 months', '3 months'), 
                           gender = c('Male', 'Female', 'Male'),
                           marital = c('Single', 'Married', 'Single'))
```

# Generate data for each category
```{r}
tempp = bag_of_words %>%
  count(parenthood, word) %>%
  group_by(parenthood) %>%
  mutate(proportion = n / sum(n)) %>%
  select(-n) %>%
  spread(parenthood, proportion)
  replace_na(list(your_first_column_name_here = 0.3, your_second_column_name_here = 0.7))

tempr = bag_of_words %>%
  count(reflection_period, word) %>%
  group_by(reflection_period) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(reflection_period, proportion)
  replace_na(list(your_first_column_name_here = 0, your_second_column_name_here = 0.4))

tempg = bag_of_words %>%
  count(gender, word) %>%
  group_by(gender) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(gender, proportion) %>% 
  replace_na(list(your_first_column_name_here = 1.3, your_second_column_name_here = 0))

tempm = bag_of_words %>%
  count(marital, word) %>%
  group_by(marital) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(marital, proportion) 
```


# Generate plots using the function
```{r}
p1 = generate_plot(tempp, "No", "Yes", "Proportion for Parenthood")
p2 = generate_plot(tempr, "24 hours", "3 months", "Proportion for Reflection")
p3 = generate_plot(tempg, "Female", "Male", "Proportion for Gender")
p4 = generate_plot(tempm, "Single", "Married", "Proportion for Marital")

# Arrange the plots
print(p1)
print(p2)
print(p3)
print(p4)

```

# Function to generate the word count plot
```{r}
generate_wordcount_plot <- function(data) {
  ggplot(data, aes(x = age_group, y = count, fill = word)) +
    geom_bar(stat = "identity") +
    facet_wrap(~ age_group, scales = "free_y") +
    labs(
      title = "Top 3 Words Used in Happy Moments by Age Group (grouped by 5 years)",
      x = "Age Group",
      y = "Word Count"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
```

# Process data and create age groups
```{r}
bag_of_words <- data.frame(age = c(21, 25, 29, 33, 21), word = c('happy', 'joy', 'fun', 'happy', 'fun'))

processed <- bag_of_words %>%
  select(age, word) %>%
  mutate(age_group = cut(age, seq(0, 100, by = 5), right = FALSE))

wc <- processed %>%
  count(age_group, word, name = "count") %>%
  arrange(desc(count))

# Get top 3 words by count for each age group
top_words <- wc %>%
  group_by(age_group) %>%
  slice_max(order_by = count, n = 3) %>%
  ungroup()

# Filter groups where sum(count) > 0 and age_group is not NA
filtered_top_words <- top_words %>%
  group_by(age_group) %>%
  filter(sum(count) > 0, !is.na(age_group)) %>%
  ungroup()
```


# Generate the plot
```{r}
p5 <- generate_wordcount_plot(filtered_top_words)
print(p5)
```



